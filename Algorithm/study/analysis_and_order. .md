# 분석과 차수
## 공간복잡도 분석
* 입력크기에 따라 메모리가 얼마나 필요한지 결정하는 절차

## 시간복잡도 분석 ⚙️
* 입력크기에 따라서 단위연산이 몇번 수행되는지 결정하는 절차

## 분석 방법의 종류
### Every-case Analysis
* 입력 크기에만 종속, 입력값과는 무관하게 결과값은 항상 일정

### Worst-case Analysis 🔧
* 알고리즘의 최악의 상황에 대한 분석
* 입력크기와 입력값 모두에 종속

### Average-case Analysis
* 입력 크기에 종속
* 모든 입력에 대해서 단위연산이 수행되는 기대치 (평균)

### Best-case Analysis
* 최선의 경우의 분석
* 입력크기와 입력값 모두에 종속

## 차수
<img width="264" alt="스크린샷 2021-10-21 오전 12 54 19" src="https://user-images.githubusercontent.com/64299475/138127993-711391ed-4f76-46e4-bc9d-05e70638c286.png">

### Big O 표기법
* O()  - big oh, 점근적 상한
* 0 <= g(n) <= c*f(n)일 때, g(n)은 f(n)의 big O가 된다.
* `ex. n^2 + 10n <= 2 * n^2이므로 n^2+10n은 n^2의 big O가 된다.`
* 실수 c > 0 중 하나만 성립하여도 된다.

### Ω 표기법 
* Ω() - omega, 점근적 하한
* g(n) >= c * f(n) >= 0 일 때, g(n)은 f(n)의 오메가 
* Big O와 반대되는 개념
* `ex. n^2 + 10 n >= n^2 이므로 n^2+10은 n^2의 오메가가 된다.`


### Θ 표기법
* Θ() - theta
* Θ(f(n)) = O(f(n)) ∩ Ω(f(n))
* c * f(n) <= g(n) <= d* f(n) 일 때, g(n)은 f(n)의 차수가 된다.

### o 표기법
* o() - small o 표기법
* 0 <= g(n) <= c*f(n) 일 때, g(n)은 f(n)의 small o 가 된다.
	* `모든 실수 c > 0 에 대해서 성립해야 한다.`

### ω 표기법
* ω() - small omega
* g(n) >= c * f(n) >= 0 일 때, g(n)은 f(n)의 스몰 오메가 
* `모든 실수 c > 0 에 대해서 성립해야 한다.`

